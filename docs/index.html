<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Generalizable Articulated Object Reconstruction from Casually Captured RGBD Videos.">
  <meta name="keywords" content="Cloth Manipulation, Learning from human Demonstration, Robot Learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Generalizable Articulated Object Reconstruction from Casually Captured RGBD Videos</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 20px;
    }
    .grid-container {
      display: grid;
      gap: 10px;
      margin-bottom: 40px;
    }
    .grid-4x4 {
      grid-template-columns: repeat(4, 1fr);
    }
    .grid-5x4 {
      grid-template-columns: repeat(5, 1fr);
    }
    .grid-item {
      text-align: center;
    }
    .grid_video {
      width: auto;
      height: 200px;
      max-height: 200px;
      border: 0px solid #ccc;
    }
    .grid-text {
      height: 200px;
      border: 0px solid #ccc;
      display: flex;
      justify-content: center;
      align-items: center;
      font-weight: bold;
      font-size: 1.2em;
    }
    .method-title {
      font-weight: bold;
      margin-bottom: 5px;
    }
  </style>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Generalizable Articulated Object Reconstruction from Casually Captured RGBD Videos</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.linkedin.com/in/weikun-peng-7731281b4/">Weikun Peng</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://lyuj1998.github.io/">Jun Lv</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.mvig.org/">Cewu Lu</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://msavva.github.io/">Manolis Savva</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Simon Fraser University,</span>
            <span class="author-block"><sup>2</sup>Shanghai Jiao Tong University</span>
          </div>

          <!-- <h1 class="title is-3 publication-title">CoRL 2024 <font color="red">(Oral)</font> </h1> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://drive.google.com/file/d/1cL99-rWxjHXbxkPXBqkm4oSalvdfFmcm/view?usp=sharing"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href="http://arxiv.org/abs/2407.03245"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href="https://youtu.be/x32Hn9BjSV0"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/3dlg-hcvc/video2articulation"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Articulated objects are prevalent in daily life. Understanding their kinematic structure and reconstructing them 
              have numerous applications in embodied AI and robotics. However, current methods require carefully captured data for training or inference, 
              preventing practical, scalable, and generalizable reconstruction of articulated objects. 
              We focus on reconstruction of an articulated object from a casually captured RGBD video shot with a hand-held camera. 
              A casually captured video of an interaction with an articulated object is easy to acquire at scale using smartphones. 
              However, this setting is quite challenging, as the object and camera move simultaneously and there are significant occlusions as the person interacts with the object. 
              To tackle these challenges, we introduce a coarse-to-fine framework that infers joint parameters and segments movable parts of the object from a dynamic RGBD video. 
              To evaluate our method under this new setting, we build a 20&times larger synthetic dataset of 784 videos containing 284 objects across 11 categories. 
              We compare our approach with existing methods that also take video as input. 
              Experiments show that our method can reconstruct synthetic and real articulated objects across different categories from dynamic RGBD videos, 
              outperforming existing methods significantly.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
          
      <!-- Paper video. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Video Summary</h2>
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/x32Hn9BjSV0?si=YW18JjoyBEOB5Fbp" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
      </div>
      <!--/ Paper video. -->
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Pipeline Overview</h2>
    <p>
      Given an casually captured RGBD video, our pipeline first estimates joint parameters and a movable part segmentation via image feature matching. 
      Then, a gradient-based optimization framework refines these initial estimates against a surface point cloud representation of the object acquired through 3D reconstruction. 
      Different from some existing work modeling articulated objects with implicit representation, our pipeline explicitly parameterizes the articulation joint parameters and other relevant parameters. 
      Moreover, our pipeline neither relies on an external library nor requires additional data for fine-tuning. Instead, it only uses pretrained models.
    </p>
    
    <!-- Coarse Prediction -->
    <div class="column">
      <h3 class="title is-4">Coarse Prediction</h3>
       <video id="coarse" controls autoplay muted loop playsinline height="100%">
        <source src="./static/videos/coarse_animation_crop.mp4"
                type="video/mp4">
      </video>
      <p>
        An overview of our coarse prediction pipeline. We first use feature matching in the static
        regions to estimate relative camera poses and align all observations to the same coordinate. Then,
        we compute the transformation using feature matching in the dynamic regions to estimate joint
        parameters for that pair of frames. Finally, we average out all the results to produce a joint parameter estimation.
      </p>
    </div>
    <!--/ Coarse Prediction -->

    <!-- Refinement -->
    <div class="column">
      <h3 class="title is-4">Refinement</h3>
        <video id="refinement" controls autoplay muted loop playsinline height="100%">
          <source src="./static/videos/refine_animation_crop.mp4"
                  type="video/mp4">
        </video>
        <p>
          An overview of our refinement pipeline. We transform observations in the video back to
          the initial stage with camera poses and joint parameters. We then compute the chamfer distance from
          the transformed observation to the object surface as a loss function and optimize relevant parameters.
        </p>
    </div>
    <!--/ Refinement -->

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Dataset Overview</h2>
    <p>
      Since the problem setting and task setup we described has not been previously addressed, we build a new dataset for evaluation. 
      We select 284 synthetic objects from 11 categories in the PartNet-Mobility dataset to generate dynamic videos for input and evaluate the performance of our method. 
      Compared to datasets used in prior works, our dataset contains 20&times more objects 
      and thus provides a more robust evaluation of the performance of different methods for reconstructing articulated objects from dynamic videos.
    </p>
    
    <!-- Data Generation Setup -->
    <div class="column">
      <h3 class="title is-4">Data Generation Setup</h3>
      <img src="./static/images/scene illustration.png" class="interpolation-image" alt="Scene inllustration" />
      <p>
        We build a simple cuboid environment in the SAPIEN simulator with realistic textures and place the object inside to manipulate it.
      </p>
      <video id="refinement" controls autoplay muted loop playsinline height="100%">
        <source src="./static/videos/data_generation_animation.mp4"
                type="video/mp4">
      </video>
      <p>
        We first render multi-view RGBD images of the object at the initial state to generate an object surface point cloud on the right-hand side. 
        Then, to increase the diversity of the video, we place two cameras in front of the moving part of the object to record the interaction videos from two different views.
      </p>
      <img src="./static/images/data distribution.svg" class="interpolation-image" alt="Data distribution" />
      <img src="./static/images/data distribution on joints.svg" class="interpolation-image" alt="Data distribution on Joints" />
      <p>
        We finally generate 784 videos of 284 objects across 11 categories. The data distribution across different categories is shown in the bar chart above.
      </p>
    </div>
    <!--/ Data Generation Setup -->

    <!-- Data Samples -->
    <div class="column">
      <h3 class="title is-4">Data Samples</h3>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-box">
          <video id="box" controls autoplay muted loop playsinline height="100%">
          <source src="./static/videos/box.mp4"
                  type="video/mp4">
        </video>
        </div>
        <div class="item dishwasher">
          <video id="dishwasher" controls autoplay muted loop playsinline height="100%">
          <source src="./static/videos/dishwasher.mp4"
                  type="video/mp4">
        </video>
        </div>
        <div class="item laptop">
          <video id="laptop" controls autoplay muted loop playsinline height="100%">
          <source src="./static/videos/laptop.mp4"
                  type="video/mp4">
        </video>
        </div>
        <div class="item scissors">
          <video id="scissors" controls autoplay muted loop playsinline height="100%">
          <source src="./static/videos/scissors.mp4"
                  type="video/mp4">
        </video>
        </div>
        <div class="item storagefurniture">
          <video id="storagefurniture" controls autoplay muted loop playsinline height="100%">
          <source src="./static/videos/storagefurniture.mp4"
                  type="video/mp4">
        </video>
        </div>
        <div class="item washingmachine">
          <video id="washingmachine" controls autoplay muted loop playsinline height="100%">
          <source src="./static/videos/washingmachine.mp4"
                  type="video/mp4">
        </video>
        </div>
      </div>
    </div>
    <!--/ Data Samples -->
  </div>
</section>

<section class="section">
  <div class="container">

    <h2 class="title is-3">Experiment Results</h2>
    
    <!-- Synthetic Data Results -->
      <h3 class="title is-4">Synthetic Data</h3>

      <div class="grid-container grid-5x4">
        <!-- Row 1 -->
        <div class="grid-item">
          <div class="method-title">Input Video</div>
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/7265/video.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="grid-item">
          <div class="method-title">Ground Truth</div>
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/7265/gt_motion.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="grid-item">
          <div class="method-title">Articulate-Anything</div>
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/7265/artany_motion.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="grid-item">
          <div class="method-title">RSRD</div>
          <img src="./static/images/7265_rsrd.png" class="interpolation-image" alt="RSRD result for microwave" />
        </div>
        <div class="grid-item">
          <div class="method-title">Ours</div>
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/7265/our_motion.mp4"
                    type="video/mp4">
          </video>
        </div>

        <!-- Row 2 -->
        <div class="grid-item">
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/103273/video.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="grid-item">
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/103273/gt_motion.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="grid-item">
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/103273/artany_motion.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="grid-item">
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/103273/rsrd_motion.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="grid-item">
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/103273/our_motion.mp4"
                    type="video/mp4">
          </video>
        </div>

        <!-- Row 3 -->
        <div class="grid-item">
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/19898/video.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="grid-item">
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/19898/gt_motion.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="grid-item">
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/19898/artany_motion.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="grid-item">
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/19898/rsrd_motion.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="grid-item">
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/19898/our_motion.mp4"
                    type="video/mp4">
          </video>
        </div>

        <!-- Row 4 -->
        <div class="grid-item">
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/100072/video.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="grid-item">
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/100072/gt_motion.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="grid-item">
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/100072/artany_motion.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="grid-item">
          <div class="grid-text">Failed</div>
        </div>
        <div class="grid-item">
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/100072/our_motion.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    <!--/ Synthetic Data Results -->

    <!-- Real Data Results. -->
      <h3 class="title is-4">Real Data</h3>
      <div class="grid-container grid-4x4">
        <!-- Row 1 -->
        <div class="grid-item">
          <div class="method-title">Input Video</div>
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/book/book2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="grid-item">
          <div class="method-title">Articulate-Anything</div>
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/book/artany_motion.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="grid-item">
          <div class="method-title">RSRD</div>
          <div class="grid-text">Failed</div>
        </div>
        <div class="grid-item">
          <div class="method-title">Ours</div>
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/book/our_motion.mp4"
                    type="video/mp4">
          </video>
        </div>

        <!-- Row 2 -->
        <div class="grid-item">
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/cabinet_door2/cabinet_door2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="grid-item">
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/cabinet_door2/artany_motion.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="grid-item">
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/cabinet_door2/rsrd_motion.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="grid-item">
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/cabinet_door2/our_motion.mp4"
                    type="video/mp4">
          </video>
        </div>

        <!-- Row 3 -->
        <div class="grid-item">
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/drawer3_2/drawer3_2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="grid-item">
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/drawer3_2/artany_motion.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="grid-item">
          <div class="grid-text">Failed</div>
        </div>
        <div class="grid-item">
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/drawer3_2/our_motion.mp4"
                    type="video/mp4">
          </video>
        </div>

        <!-- Row 4 -->
        <div class="grid-item">
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/room_storage/room_storage.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="grid-item">
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/room_storage/artany_motion.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="grid-item">
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/room_storage/rsrd_motion.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="grid-item">
          <video class="grid_video" controls autoplay muted loop playsinline>
            <source src="./static/videos/room_storage/our_motion.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    <!--/ Real Data Results. -->

  </div>

</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Acknowledgments</h2>
        <div class="content has-text-justified">
          <p>
            This work was funded in part by a Canada Research Chair, NSERC Discovery Grant, and enabled by support from the Digital Research Alliance of Canada.
            The authors would like to thank Jiayi Liu, Xingguang Yan, Austin T. Wang, Hou In Ivan Tam, Morteza Badali for valuable discussions, and Yi Shi for proofreading.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code></code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is modified from <a
            href="https://nerfies.github.io/">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
